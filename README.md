# llama3

Ollama config:

1. Download & install ollama
2. run models

```
ollama run llama3
```

## Node run

```
yarn dev
```

or

```
npm run dev
```
